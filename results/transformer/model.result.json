{
    "name": "Transformer",
    "title": "Transformer",
    "description": "Decoder stack from 'Attention Is All You Need'.",
    "authors": [
        "Ashish Vaswani",
        "Noam Shazeer",
        "Niki Parmar",
        "Jakob Uszkoreit",
        "Llion Jones",
        "Aidan N. Gomez",
        "Lukasz Kaiser",
        "Illia Polosukhin"
    ],
    "paper": "https://arxiv.org/abs/1706.03762",
    "variations": {
        "default": {
            "arguments": {
                "dims": 48,
                "q_heads": 8,
                "kv_heads": 8,
                "blocks": 8,
                "base_freq": 10000
            },
            "metrics": {
                "Memory Capacity": 0.9451978499011041,
                "State Management": 0.9887002233361999,
                "Placeholder Ability": 0.9887002233361999
            },
            "model_stats": {
                "size": 4002560,
                "size_doubling_rate": 0.0,
                "size_big_o": "???",
                "flops": 36455333888,
                "flops_doubling_rate": 1.4299999475479126,
                "flops_big_o": "???"
            }
        }
    }
}